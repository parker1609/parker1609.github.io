<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Spring Boot에서 카프카 사용하기 | Parker Blog</title><meta name=keywords content="Spring Boot,Kafka,PostgreSQL"><meta name=description content="이 글의 코드는 해당 링크에서 확인할 수 있습니다.
목표 Spring Boot 에서 Apache Kafka 사용 방법
자주 사용하는 설정 정리
테스트 개발 환경 Spring Boot 3.1.0
Java 17
Spring Kafka 3.0.7
kafka-client 3.4.0 Gradle
Docker
Broker 테스트 개발 환경에서는 카프카를 로컬에서 Docker 파일로 띄우고, Spring 서버에서 이를 연결한다.
로컬에서 Docker로 Apache Kafka 실행하기 kafka docker image 비교 bitnami
confluentinc
wurstmeister
링크 다운로드 수 star 수 특징 confluentinc DockerDocker 100M+ 394 confluent 에서 제공하는 기능이 포함 bitnami DockerDocker 100M+ 669 순수 카프카 이미지 wurstmeister DockerDocker 100M+ 1."><meta name=author content="parker1609"><link rel=canonical href=https://parker1609.github.io/post/spring-boot-kafka/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://parker1609.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://parker1609.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://parker1609.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://parker1609.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://parker1609.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Spring Boot에서 카프카 사용하기"><meta property="og:description" content="이 글의 코드는 해당 링크에서 확인할 수 있습니다.
목표 Spring Boot 에서 Apache Kafka 사용 방법
자주 사용하는 설정 정리
테스트 개발 환경 Spring Boot 3.1.0
Java 17
Spring Kafka 3.0.7
kafka-client 3.4.0 Gradle
Docker
Broker 테스트 개발 환경에서는 카프카를 로컬에서 Docker 파일로 띄우고, Spring 서버에서 이를 연결한다.
로컬에서 Docker로 Apache Kafka 실행하기 kafka docker image 비교 bitnami
confluentinc
wurstmeister
링크 다운로드 수 star 수 특징 confluentinc DockerDocker 100M+ 394 confluent 에서 제공하는 기능이 포함 bitnami DockerDocker 100M+ 669 순수 카프카 이미지 wurstmeister DockerDocker 100M+ 1."><meta property="og:type" content="article"><meta property="og:url" content="https://parker1609.github.io/post/spring-boot-kafka/"><meta property="og:image" content="https://parker1609.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-05-29T10:27:57+09:00"><meta property="article:modified_time" content="2023-05-29T10:27:57+09:00"><meta property="og:site_name" content="Parker Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://parker1609.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Spring Boot에서 카프카 사용하기"><meta name=twitter:description content="이 글의 코드는 해당 링크에서 확인할 수 있습니다.
목표 Spring Boot 에서 Apache Kafka 사용 방법
자주 사용하는 설정 정리
테스트 개발 환경 Spring Boot 3.1.0
Java 17
Spring Kafka 3.0.7
kafka-client 3.4.0 Gradle
Docker
Broker 테스트 개발 환경에서는 카프카를 로컬에서 Docker 파일로 띄우고, Spring 서버에서 이를 연결한다.
로컬에서 Docker로 Apache Kafka 실행하기 kafka docker image 비교 bitnami
confluentinc
wurstmeister
링크 다운로드 수 star 수 특징 confluentinc DockerDocker 100M+ 394 confluent 에서 제공하는 기능이 포함 bitnami DockerDocker 100M+ 669 순수 카프카 이미지 wurstmeister DockerDocker 100M+ 1."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://parker1609.github.io/post/"},{"@type":"ListItem","position":2,"name":"Spring Boot에서 카프카 사용하기","item":"https://parker1609.github.io/post/spring-boot-kafka/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Spring Boot에서 카프카 사용하기","name":"Spring Boot에서 카프카 사용하기","description":"이 글의 코드는 해당 링크에서 확인할 수 있습니다.\n목표 Spring Boot 에서 Apache Kafka 사용 방법\n자주 사용하는 설정 정리\n테스트 개발 환경 Spring Boot 3.1.0\nJava 17\nSpring Kafka 3.0.7\nkafka-client 3.4.0 Gradle\nDocker\nBroker 테스트 개발 환경에서는 카프카를 로컬에서 Docker 파일로 띄우고, Spring 서버에서 이를 연결한다.\n로컬에서 Docker로 Apache Kafka 실행하기 kafka docker image 비교 bitnami\nconfluentinc\nwurstmeister\n\u0008링크 다운로드 수 star 수 특징 confluentinc DockerDocker 100M+ 394 confluent 에서 제공하는 기능이 포함 bitnami DockerDocker 100M+ 669 순수 카프카 이미지 wurstmeister DockerDocker 100M+ 1.","keywords":["Spring Boot","Kafka","PostgreSQL"],"articleBody":" 이 글의 코드는 해당 링크에서 확인할 수 있습니다.\n목표 Spring Boot 에서 Apache Kafka 사용 방법\n자주 사용하는 설정 정리\n테스트 개발 환경 Spring Boot 3.1.0\nJava 17\nSpring Kafka 3.0.7\nkafka-client 3.4.0 Gradle\nDocker\nBroker 테스트 개발 환경에서는 카프카를 로컬에서 Docker 파일로 띄우고, Spring 서버에서 이를 연결한다.\n로컬에서 Docker로 Apache Kafka 실행하기 kafka docker image 비교 bitnami\nconfluentinc\nwurstmeister\n\u0008링크 다운로드 수 star 수 특징 confluentinc DockerDocker 100M+ 394 confluent 에서 제공하는 기능이 포함 bitnami DockerDocker 100M+ 669 순수 카프카 이미지 wurstmeister DockerDocker 100M+ 1.6K 순수 카프카 이미지 confluetntinc 이미지는 컨플루언트에서 제공하는 기능을 사용할 수 있는 이미지이다. 나머지 bitnami와 wurstmeister 이미지는 둘 다 순수하게 Apache Kafka 이미지를 담은 것으로 둘 중 아무거나 사용해도 될 듯하다.\n카프카는 카프카의 메타 데이터를 관리해주는 zookeeper와 함께 동작한다. 따라서 카프카 브로커와 같이 실행을 해주어야 하는데, 둘 다 docker를 따로 실행해주기보다는 docker-compose 파일을 만들어서 같이 편리하게 실행해주는 설정파일을 만들었다.\nKafka docker 이미지마다 환경 설정 중 필수요소가 다르다. 예를 들어, wurstmeister 이미지는 KAFKA_LISTENERS 설정이 필수로 필요하다. 이는 문서를 참고하거나 실행해보고 docker container의 로그를 살펴보는 것도 방법이다.\n아래는 confluentinc와 wurstmeister 이미지를 사용한 docker-compose 파일이다.\nversion: '2' services: zookeeper: image: confluentinc/cp-zookeeper:latest environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 ports: - 22181:2181 # Mac M1 chip 사용 시 아래 platform 추가 platform: linux/amd64 kafka: image: confluentinc/cp-kafka:latest depends_on: - zookeeper ports: - 29092:29092 environment: KAFKA_BROKER_ID: 1 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 version: '3' services: zookeeper: image: wurstmeister/zookeeper container_name: zookeeper ports: - \"2181:2181\" # Mac M1 chip 사용 시 아래 platform 추가 platform: linux/amd64 kafka: image: wurstmeister/kafka container_name: kafka ports: - \"9092:9092\" environment: KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092 KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_AUTO_CREATE_TOPICS_ENABLE: true depends_on: - zookeeper # docker-compose 실행 docker-compose up -d # docker container 확인 docker ps # docker-compose 종료 docker-compose down 참고자료 [Kafka] Docker Compose 를 이용하여 Single Broker 구성하기\nGuide to Setting Up Apache Kafka Using Docker | Baeldung\nKafka를 docker로 배포하고, Springboot 테스트 프로젝트 만들기 - Dev Log\nSpring Boot에서 Kafka Broker 연결하기 Spring Boot 환경에서는 application.yml 파일을 통해 최대한 자동 설정을 하는 것이 좋다.\nSpring Boot를 사용하는 큰 이유이기도 하며, 보통 개발자들은 Spring Boot 프로젝트 설정을은 application.yml (or application.properties)에 선언한다고 보통 생각하므로 여기서 찾는다.\nspring: kafa: bootstrap-servers: - localhost:9092 broker 설정만 가지고는 스프링을 실행해도 로그에는 딱히 카프카가 연동되었다거나 하는 정보를 찾아볼 수 없다. Spring kafka는 기본적으로 카프카에 대한 요청이 있을 때, 카프카를 연동한다. 따라서 컨슈머를 설정하면, 컨슈머는 바로 실행이 필요하므로 스프링을 띄울 때 연동되는 것을 확인할 수 있고, 프로듀서는 프로듀서가 실행될 때, 카프카 연동을 하는 것을 볼 수 있다.\n간단한 Producer \u0026 Consumer 예제 실제로 연동한 Kafka broker가 정상적으로 동작하는지 간단한 프로듀서와 컨슈머 예제를 살펴보자. 토픽에 하나에 문자열 데이터를 전송 및 소비하는 예제이고, 프로듀서의 트리거는 HTTP API이다.\n먼저, Producer 예제이다.\nspring: kafka: bootstrap-servers: - localhost:9092 producer: key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer application.yml에 프로듀서 관련 설정이다. 이 예제에서는 간단히 메시지에 대한 직렬화 설정만 했다. 위는 String으로 직렬화를 한다는 설정이고, 사실 이는 기본 설정이라 설정을 해주지 않아도 문제는 없다.\n@Slf4j @RequiredArgsConstructor @Component public class KafkaProducer { private final KafkaTemplate\u003cString, String\u003e kafkaTemplate; public void sendMessage(String topic, String message) { kafkaTemplate.send(topic, message); log.info(\"Message sent: {}\", message); } } 실제로 카프카에 메시지를 보내는 코드이다. KafkaTemplate 을 사용해서 key, value 모두 String 문자열로 보낸다.\n@RequiredArgsConstructor @RestController @RequestMapping(\"messages\") public class MessageController { private final KafkaProducer kafkaProducer; @PostMapping public void sendMessage(@RequestBody String message) { kafkaProducer.sendMessage(\"my-topic\", message); } } 위는 HTTP API를 호출했을 때, 카프카에 메시지를 보내는 코드이다. POST 요청으로 request body에 선언된 문자열을 카프카 메시지로 보낸다.\n다음은 Consumer 예제이다.\n위 Producer 예제에서 카프카 브로커에 문자열 데이터를 보냈고, 이를 소비해서 사용하는 컨슈머 예제이다.\nspring: kafka: bootstrap-servers: - localhost:9092 listener: type: batch consumer: key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer application.yml 설정부터 살펴보자. consumer 외에도 listener 라는 설정이 있는데, Spring Kafka는 카프카 리스너를 통해 카프카 브로커로부터 데이터를 읽은 역할을 하고, 컨슈머는 카프카 브로커 내의 토픽에서 메시지를 소비하는 역할을 한다. 정리하면 리스터는 데이터를 가져오고, 컨슈머는 가져온 데이터를 사용한다.\n위 설정은 리스너는 카브카 브로커로부터 batch 타입으로 가져오는데, 이는 단일이 아닌 여러 개의 데이터를 가져오겠다는 의미이다. 컨슈머는 단순히 프로듀서와 같이 역직렬화에 대한 설정이고, 기본 설정과 같다.\nProducer, Listener, Consumer에 대한 자세한 설정은 아래에서 살펴볼 예정이다.\n@Slf4j @Component public class KafkaConsumer { @KafkaListener(topics = \"my-topic\", groupId = \"my-group-id\") public void consume(String message) { log.info(\"Received message: {}\", message); // 메시지 처리 로직을 작성합니다. } } @KafkaListener 애노테이션으로도 컨슈머에 대한 설정을 할 수 있다. 위는 토픽과 컨슈머 그룹 ID를 애노테이션에 설정한 모습이다. 이러한 애노테이션 설정으로 하나의 서버에서 여러 개의 서로 다른 토픽 및 컨슈머 그룹 ID를 설정해서 사용할 수 있다.\n이제 설정한 프로듀서와 컨슈머 테스트를 해보자.\n먼저, 서버를 실행해보자.\n2023-05-29T09:20:57.012+09:00 INFO 10791 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer : my-group-id: partitions assigned: [my-topic-0] 서버를 실행하면, 카프카 컨슈머에 대한 설정을 보여주고 위 로그처럼 @KafkaListener 애노테이션으로 설정한 토픽과 컨슈머 그룹 ID가 정상적으로 할당되었다는 것을 알 수 있다.\n이제 Producer를 동작시키는 컨트롤러에 HTTP API 요청을 보내서 메시지를 카프카에 produe하고, 이를 consume하는 것을 해보자.\nIntelliJ IDEA를 사용하면, IDE 내에서 .http 파일에서 HTTP 요청을 보낼 수 있다.\nPOST http://localhost:8090/messages Content-Type: application/json \"Hello Kafka!\" 위를 실행해보면, 스프링 서버에서 카프카 프로듀서가 연결되어 컨슈머와 같이 설정들을 보여줄 것이다.\n2023-05-29T09:23:41.221+09:00 INFO 10791 --- [nio-8090-exec-1] m.p.s.KafkaProducer : Message sent: \"Hello Kafka!\" 2023-05-29T09:23:41.234+09:00 INFO 10791 --- [ntainer#0-0-C-1] m.p.s.KafkaConsumer : Received message: \"Hello Kafka!\" 그리고 위 로그와 같이 프로듀서와 컨슈머에 각각 추가해둔 로그가 정상적으로 실행된 것을 볼 수 있다.\n모니터링 (w. 오픈소스) 카프카는 여러 오픈소스 모니터링이 존재한다. (카프카 모니터링 도구 비교)\nKafka-ui 여기서는 Kafka-ui를 사용해볼 것이다. 이는 현재도 활발히 개발중인 것으로 보인다.\n\u003cGitHub - provectus/kafka-ui: Open-Source Web UI for Apache Kafka Management\u003e\nAbout - UI for Apache Kafka\n장점: UI가 세련되었고 간편하며, 다양한 기능이 존재한다.\n단점: 현재도 개발 중… (이는 장점이 될 수도 있을 듯 함.)\n사용방법은 docker를 사용할 것이고, 기존 docker-compose 파일에 추가해보자.\nversion: '3' services: zookeeper: image: wurstmeister/zookeeper container_name: zookeeper ports: - \"2181:2181\" # Mac M1 chip 사용 시 아래 platform 추가 platform: linux/amd64 kafka: image: wurstmeister/kafka container_name: kafka ports: - \"9092:9092\" environment: KAFKA_ADVERTISED_LISTENERS: INSIDE://:29092,OUTSIDE://localhost:9092 KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://0.0.0.0:9092 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_AUTO_CREATE_TOPICS_ENABLE: true depends_on: - zookeeper kafka-ui: container_name: kafka-ui image: provectuslabs/kafka-ui:latest ports: - \"8080:8080\" depends_on: - kafka environment: DYNAMIC_CONFIG_ENABLED: 'true' KAFKA_CLUSTERS_0_NAME: wizard_local KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092 kafka를 외부와 내부 리스너를 나누었다.\nkafka-ui는 내부 카프카 리스너와 통신을 하고, Spring Boot 서버는 외부 카프카 리스너와 통신한다.\n위로 변경 후, 다시 docker를 실행하고, http://localhost:8080 에 접속해보자.\n메인 화면을 보면, cluster-name에 설정한 ‘wizard_local’을 볼 수 있다. 정상적으로 카프카와 연결된 것을 알 수 있다.\n다시 한 번 예제에서 “Hello Kafka” 메시지를 만들어보자. (재실행했기 때문에 이전에 테스트했던 데이터는 초기화된 상태이다.)\n그러면 다음과 같이 토픽 내에 메시지가 정상적으로 쌓인 것을 볼 수 있다.\nRedpanda 추가 예정\nProducer 설정 추가 예정\nConsumer 설정 추가 예정\n","wordCount":"1057","inLanguage":"en","datePublished":"2023-05-29T10:27:57+09:00","dateModified":"2023-05-29T10:27:57+09:00","author":{"@type":"Person","name":"parker1609"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://parker1609.github.io/post/spring-boot-kafka/"},"publisher":{"@type":"Organization","name":"Parker Blog","logo":{"@type":"ImageObject","url":"https://parker1609.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://parker1609.github.io/ accesskey=h title="파커 블로그 (Alt + H)"><img src=https://parker1609.github.io/apple-touch-icon.png alt aria-label=logo height=35>파커 블로그</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://parker1609.github.io/ title=Home><span>Home</span></a></li><li><a href=https://parker1609.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://parker1609.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://parker1609.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://parker1609.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://parker1609.github.io/post/>Posts</a></div><h1 class=post-title>Spring Boot에서 카프카 사용하기</h1><div class=post-meta><span title='2023-05-29 10:27:57 +0900 KST'>May 29, 2023</span>&nbsp;·&nbsp;parker1609</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%eb%aa%a9%ed%91%9c aria-label=목표>목표</a></li><li><a href=#%ed%85%8c%ec%8a%a4%ed%8a%b8-%ea%b0%9c%eb%b0%9c-%ed%99%98%ea%b2%bd aria-label="테스트 개발 환경">테스트 개발 환경</a></li><li><a href=#broker aria-label=Broker>Broker</a><ul><li><a href=#%eb%a1%9c%ec%bb%ac%ec%97%90%ec%84%9c-docker%eb%a1%9c-apache-kafka-%ec%8b%a4%ed%96%89%ed%95%98%ea%b8%b0 aria-label="로컬에서 Docker로 Apache Kafka 실행하기">로컬에서 Docker로 Apache Kafka 실행하기</a><ul><li><a href=#kafka-docker-image-%eb%b9%84%ea%b5%90 aria-label="kafka docker image 비교">kafka docker image 비교</a></li><li><a href=#%ec%b0%b8%ea%b3%a0%ec%9e%90%eb%a3%8c aria-label=참고자료>참고자료</a></li></ul></li><li><a href=#spring-boot%ec%97%90%ec%84%9c-kafka-broker-%ec%97%b0%ea%b2%b0%ed%95%98%ea%b8%b0 aria-label="Spring Boot에서 Kafka Broker 연결하기">Spring Boot에서 Kafka Broker 연결하기</a></li><li><a href=#%ea%b0%84%eb%8b%a8%ed%95%9c-producer--consumer-%ec%98%88%ec%a0%9c aria-label="간단한 Producer &amp;amp; Consumer 예제">간단한 Producer & Consumer 예제</a></li></ul></li><li><a href=#%eb%aa%a8%eb%8b%88%ed%84%b0%eb%a7%81-w-%ec%98%a4%ed%94%88%ec%86%8c%ec%8a%a4 aria-label="모니터링 (w. 오픈소스)">모니터링 (w. 오픈소스)</a><ul><li><a href=#kafka-ui aria-label=Kafka-ui>Kafka-ui</a></li><li><a href=#redpanda aria-label=Redpanda>Redpanda</a></li></ul></li><li><a href=#producer-%ec%84%a4%ec%a0%95 aria-label="Producer 설정">Producer 설정</a></li><li><a href=#consumer-%ec%84%a4%ec%a0%95 aria-label="Consumer 설정">Consumer 설정</a></li></ul></div></details></div><div class=post-content><blockquote><p>이 글의 코드는 해당 <a href=https://github.com/parker1609/...>링크</a>에서 확인할 수 있습니다.</p></blockquote><h1 id=목표>목표<a hidden class=anchor aria-hidden=true href=#목표>#</a></h1><ul><li><p>Spring Boot 에서 Apache Kafka 사용 방법</p></li><li><p>자주 사용하는 설정 정리</p></li></ul><h1 id=테스트-개발-환경>테스트 개발 환경<a hidden class=anchor aria-hidden=true href=#테스트-개발-환경>#</a></h1><ul><li><p>Spring Boot 3.1.0</p></li><li><p>Java 17</p></li><li><p>Spring Kafka 3.0.7</p><ul><li>kafka-client 3.4.0</li></ul></li><li><p>Gradle</p></li><li><p>Docker</p></li></ul><h1 id=broker>Broker<a hidden class=anchor aria-hidden=true href=#broker>#</a></h1><p>테스트 개발 환경에서는 카프카를 로컬에서 Docker 파일로 띄우고, Spring 서버에서 이를 연결한다.</p><h2 id=로컬에서-docker로-apache-kafka-실행하기>로컬에서 Docker로 Apache Kafka 실행하기<a hidden class=anchor aria-hidden=true href=#로컬에서-docker로-apache-kafka-실행하기>#</a></h2><h3 id=kafka-docker-image-비교>kafka docker image 비교<a hidden class=anchor aria-hidden=true href=#kafka-docker-image-비교>#</a></h3><ul><li><p>bitnami</p></li><li><p>confluentinc</p></li><li><p>wurstmeister</p></li></ul><table><thead><tr><th></th><th>링크</th><th>다운로드 수</th><th>star 수</th><th>특징</th></tr></thead><tbody><tr><td>confluentinc</td><td><a href=https://hub.docker.com/r/confluentinc/cp-kafka>Docker</a><a href=https://hub.docker.com/r/confluentinc/cp-zookeeper>Docker</a></td><td>100M+</td><td>394</td><td>confluent 에서 제공하는 기능이 포함</td></tr><tr><td>bitnami</td><td><a href=https://hub.docker.com/r/bitnami/kafka>Docker</a><a href=https://hub.docker.com/r/bitnami/zookeeper>Docker</a></td><td>100M+</td><td>669</td><td>순수 카프카 이미지</td></tr><tr><td>wurstmeister</td><td><a href=https://hub.docker.com/r/wurstmeister/kafka>Docker</a><a href=https://hub.docker.com/r/wurstmeister/zookeeper>Docker</a></td><td>100M+</td><td>1.6K</td><td>순수 카프카 이미지</td></tr></tbody></table><p>confluetntinc 이미지는 컨플루언트에서 제공하는 기능을 사용할 수 있는 이미지이다. 나머지 bitnami와 wurstmeister 이미지는 둘 다 순수하게 Apache Kafka 이미지를 담은 것으로 둘 중 아무거나 사용해도 될 듯하다.</p><p>카프카는 카프카의 메타 데이터를 관리해주는 zookeeper와 함께 동작한다. 따라서 카프카 브로커와 같이 실행을 해주어야 하는데, 둘 다 docker를 따로 실행해주기보다는 docker-compose 파일을 만들어서 같이 편리하게 실행해주는 설정파일을 만들었다.</p><p>Kafka docker 이미지마다 환경 설정 중 필수요소가 다르다. 예를 들어, wurstmeister 이미지는 KAFKA_LISTENERS 설정이 필수로 필요하다. 이는 문서를 참고하거나 실행해보고 docker container의 로그를 살펴보는 것도 방법이다.</p><p>아래는 confluentinc와 wurstmeister 이미지를 사용한 docker-compose 파일이다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl>version: <span class=s1>&#39;2&#39;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>services:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  zookeeper:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    image: confluentinc/cp-zookeeper:latest<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    environment:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      ZOOKEEPER_CLIENT_PORT: <span class=m>2181</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      ZOOKEEPER_TICK_TIME: <span class=m>2000</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    ports:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      - 22181:2181<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    <span class=c1># Mac M1 chip 사용 시 아래 platform 추가</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    platform: linux/amd64<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  kafka:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    image: confluentinc/cp-kafka:latest<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    depends_on:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      - zookeeper<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    ports:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      - 29092:29092<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    environment:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_BROKER_ID: <span class=m>1</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: <span class=m>1</span><span class=err>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl>version: <span class=s1>&#39;3&#39;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>services:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  zookeeper:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    image: wurstmeister/zookeeper<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    container_name: zookeeper<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    ports:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      - <span class=s2>&#34;2181:2181&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    <span class=c1># Mac M1 chip 사용 시 아래 platform 추가</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    platform: linux/amd64<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>  kafka:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    image: wurstmeister/kafka<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    container_name: kafka<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    ports:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      - <span class=s2>&#34;9092:9092&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    environment:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_ADVERTISED_PORT: <span class=m>9092</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>    depends_on:<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>      - zookeeper<span class=err>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># docker-compose 실행 </span>
</span></span><span class=line><span class=cl>docker-compose up -d
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># docker container 확인 </span>
</span></span><span class=line><span class=cl>docker ps
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#  docker-compose 종료</span>
</span></span><span class=line><span class=cl>docker-compose down
</span></span></code></pre></div><h3 id=참고자료>참고자료<a hidden class=anchor aria-hidden=true href=#참고자료>#</a></h3><p><a href="https://devocean.sk.com/blog/techBoardDetail.do?ID=164007">[Kafka] Docker Compose 를 이용하여 Single Broker 구성하기</a></p><p><a href=https://www.baeldung.com/ops/kafka-docker-setup>Guide to Setting Up Apache Kafka Using Docker | Baeldung</a></p><p><a href=https://yongil76.github.io/kafka/Kafka_Start/>Kafka를 docker로 배포하고, Springboot 테스트 프로젝트 만들기 - Dev Log</a></p><h2 id=spring-boot에서-kafka-broker-연결하기>Spring Boot에서 Kafka Broker 연결하기<a hidden class=anchor aria-hidden=true href=#spring-boot에서-kafka-broker-연결하기>#</a></h2><p>Spring Boot 환경에서는 application.yml 파일을 통해 최대한 자동 설정을 하는 것이 좋다.</p><blockquote><p>Spring Boot를 사용하는 큰 이유이기도 하며, 보통 개발자들은 Spring Boot 프로젝트 설정을은 application.yml (or application.properties)에 선언한다고 보통 생각하므로 여기서 찾는다.</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>spring</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafa</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>bootstrap-servers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>localhost:9092</span><span class=w>
</span></span></span></code></pre></div><p>broker 설정만 가지고는 스프링을 실행해도 로그에는 딱히 카프카가 연동되었다거나 하는 정보를 찾아볼 수 없다. Spring kafka는 기본적으로 카프카에 대한 요청이 있을 때, 카프카를 연동한다. 따라서 컨슈머를 설정하면, 컨슈머는 바로 실행이 필요하므로 스프링을 띄울 때 연동되는 것을 확인할 수 있고, 프로듀서는 프로듀서가 실행될 때, 카프카 연동을 하는 것을 볼 수 있다.</p><h2 id=간단한-producer--consumer-예제>간단한 Producer & Consumer 예제<a hidden class=anchor aria-hidden=true href=#간단한-producer--consumer-예제>#</a></h2><p>실제로 연동한 Kafka broker가 정상적으로 동작하는지 간단한 프로듀서와 컨슈머 예제를 살펴보자. 토픽에 하나에 문자열 데이터를 전송 및 소비하는 예제이고, 프로듀서의 트리거는 HTTP API이다.</p><p>먼저, Producer 예제이다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>spring</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>bootstrap-servers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>localhost:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>producer</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>key-serializer</span><span class=p>:</span><span class=w> </span><span class=l>org.apache.kafka.common.serialization.StringSerializer</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value-serializer</span><span class=p>:</span><span class=w> </span><span class=l>org.apache.kafka.common.serialization.StringSerializer</span><span class=w>
</span></span></span></code></pre></div><p>application.yml에 프로듀서 관련 설정이다. 이 예제에서는 간단히 메시지에 대한 직렬화 설정만 했다. 위는 String으로 직렬화를 한다는 설정이고, 사실 이는 기본 설정이라 설정을 해주지 않아도 문제는 없다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@Slf4j</span>
</span></span><span class=line><span class=cl><span class=nd>@RequiredArgsConstructor</span>
</span></span><span class=line><span class=cl><span class=nd>@Component</span>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=kd>class</span> <span class=nc>KafkaProducer</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>private</span> <span class=kd>final</span> <span class=n>KafkaTemplate</span><span class=o>&lt;</span><span class=n>String</span><span class=o>,</span> <span class=n>String</span><span class=o>&gt;</span> <span class=n>kafkaTemplate</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>sendMessage</span><span class=o>(</span><span class=n>String</span> <span class=n>topic</span><span class=o>,</span> <span class=n>String</span> <span class=n>message</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>kafkaTemplate</span><span class=o>.</span><span class=na>send</span><span class=o>(</span><span class=n>topic</span><span class=o>,</span> <span class=n>message</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=n>log</span><span class=o>.</span><span class=na>info</span><span class=o>(</span><span class=s>&#34;Message sent: {}&#34;</span><span class=o>,</span> <span class=n>message</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>실제로 카프카에 메시지를 보내는 코드이다. <code>KafkaTemplate</code> 을 사용해서 key, value 모두 String 문자열로 보낸다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@RequiredArgsConstructor</span>
</span></span><span class=line><span class=cl><span class=nd>@RestController</span>
</span></span><span class=line><span class=cl><span class=nd>@RequestMapping</span><span class=o>(</span><span class=s>&#34;messages&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=kd>class</span> <span class=nc>MessageController</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>private</span> <span class=kd>final</span> <span class=n>KafkaProducer</span> <span class=n>kafkaProducer</span><span class=o>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@PostMapping</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>sendMessage</span><span class=o>(</span><span class=nd>@RequestBody</span> <span class=n>String</span> <span class=n>message</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>kafkaProducer</span><span class=o>.</span><span class=na>sendMessage</span><span class=o>(</span><span class=s>&#34;my-topic&#34;</span><span class=o>,</span> <span class=n>message</span><span class=o>);</span>
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>위는 HTTP API를 호출했을 때, 카프카에 메시지를 보내는 코드이다. POST 요청으로 request body에 선언된 문자열을 카프카 메시지로 보낸다.</p><p>다음은 Consumer 예제이다.</p><p>위 Producer 예제에서 카프카 브로커에 문자열 데이터를 보냈고, 이를 소비해서 사용하는 컨슈머 예제이다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>spring</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>kafka</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>bootstrap-servers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>localhost:9092</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>listener</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>batch</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>consumer</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>key-deserializer</span><span class=p>:</span><span class=w> </span><span class=l>org.apache.kafka.common.serialization.StringDeserializer</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value-deserializer</span><span class=p>:</span><span class=w> </span><span class=l>org.apache.kafka.common.serialization.StringDeserializer</span><span class=w>
</span></span></span></code></pre></div><p>application.yml 설정부터 살펴보자. consumer 외에도 listener 라는 설정이 있는데, Spring Kafka는 카프카 리스너를 통해 카프카 브로커로부터 데이터를 읽은 역할을 하고, 컨슈머는 카프카 브로커 내의 토픽에서 메시지를 소비하는 역할을 한다. 정리하면 리스터는 데이터를 가져오고, 컨슈머는 가져온 데이터를 사용한다.</p><p>위 설정은 리스너는 카브카 브로커로부터 batch 타입으로 가져오는데, 이는 단일이 아닌 여러 개의 데이터를 가져오겠다는 의미이다. 컨슈머는 단순히 프로듀서와 같이 역직렬화에 대한 설정이고, 기본 설정과 같다.</p><p>Producer, Listener, Consumer에 대한 자세한 설정은 아래에서 살펴볼 예정이다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=nd>@Slf4j</span>
</span></span><span class=line><span class=cl><span class=nd>@Component</span>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=kd>class</span> <span class=nc>KafkaConsumer</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@KafkaListener</span><span class=o>(</span><span class=n>topics</span> <span class=o>=</span> <span class=s>&#34;my-topic&#34;</span><span class=o>,</span> <span class=n>groupId</span> <span class=o>=</span> <span class=s>&#34;my-group-id&#34;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>consume</span><span class=o>(</span><span class=n>String</span> <span class=n>message</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>        <span class=n>log</span><span class=o>.</span><span class=na>info</span><span class=o>(</span><span class=s>&#34;Received message: {}&#34;</span><span class=o>,</span> <span class=n>message</span><span class=o>);</span>
</span></span><span class=line><span class=cl>        <span class=c1>// 메시지 처리 로직을 작성합니다.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=o>}</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p><code>@KafkaListener</code> 애노테이션으로도 컨슈머에 대한 설정을 할 수 있다. 위는 토픽과 컨슈머 그룹 ID를 애노테이션에 설정한 모습이다. 이러한 애노테이션 설정으로 하나의 서버에서 여러 개의 서로 다른 토픽 및 컨슈머 그룹 ID를 설정해서 사용할 수 있다.</p><p>이제 설정한 프로듀서와 컨슈머 테스트를 해보자.</p><p>먼저, 서버를 실행해보자.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>2023-05-29T09:20:57.012+09:00  INFO <span class=m>10791</span> --- <span class=o>[</span>ntainer#0-0-C-1<span class=o>]</span> o.s.k.l.KafkaMessageListenerContainer    : my-group-id: partitions assigned: <span class=o>[</span>my-topic-0<span class=o>]</span>
</span></span></code></pre></div><p>서버를 실행하면, 카프카 컨슈머에 대한 설정을 보여주고 위 로그처럼 <code>@KafkaListener</code> 애노테이션으로 설정한 토픽과 컨슈머 그룹 ID가 정상적으로 할당되었다는 것을 알 수 있다.</p><p>이제 Producer를 동작시키는 컨트롤러에 HTTP API 요청을 보내서 메시지를 카프카에 produe하고, 이를 consume하는 것을 해보자.</p><p>IntelliJ IDEA를 사용하면, IDE 내에서 .http 파일에서 HTTP 요청을 보낼 수 있다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-http data-lang=http><span class=line><span class=cl><span class=err>POST http://localhost:8090/messages
</span></span></span><span class=line><span class=cl><span class=err>Content-Type: application/json
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>&#34;Hello Kafka!&#34;
</span></span></span></code></pre></div><p>위를 실행해보면, 스프링 서버에서 카프카 프로듀서가 연결되어 컨슈머와 같이 설정들을 보여줄 것이다.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>2023-05-29T09:23:41.221+09:00  INFO <span class=m>10791</span> --- <span class=o>[</span>nio-8090-exec-1<span class=o>]</span> m.p.s.KafkaProducer                      : Message sent: <span class=s2>&#34;Hello Kafka!&#34;</span>
</span></span><span class=line><span class=cl>2023-05-29T09:23:41.234+09:00  INFO <span class=m>10791</span> --- <span class=o>[</span>ntainer#0-0-C-1<span class=o>]</span> m.p.s.KafkaConsumer                      : Received message: <span class=s2>&#34;Hello Kafka!&#34;</span>
</span></span></code></pre></div><p>그리고 위 로그와 같이 프로듀서와 컨슈머에 각각 추가해둔 로그가 정상적으로 실행된 것을 볼 수 있다.</p><h1 id=모니터링-w-오픈소스>모니터링 (w. 오픈소스)<a hidden class=anchor aria-hidden=true href=#모니터링-w-오픈소스>#</a></h1><p>카프카는 여러 오픈소스 모니터링이 존재한다. (<a href=https://towardsdatascience.com/overview-of-ui-tools-for-monitoring-and-management-of-apache-kafka-clusters-8c383f897e80>카프카 모니터링 도구 비교</a>)</p><h2 id=kafka-ui>Kafka-ui<a hidden class=anchor aria-hidden=true href=#kafka-ui>#</a></h2><p>여기서는 Kafka-ui를 사용해볼 것이다. 이는 현재도 활발히 개발중인 것으로 보인다.</p><ul><li><p>&lt;<a href=https://github.com/provectus/kafka-ui>GitHub - provectus/kafka-ui: Open-Source Web UI for Apache Kafka Management</a>></p></li><li><p><a href=https://docs.kafka-ui.provectus.io/overview/readme>About - UI for Apache Kafka</a></p></li><li><p>장점: UI가 세련되었고 간편하며, 다양한 기능이 존재한다.</p></li><li><p>단점: 현재도 개발 중&mldr; (이는 장점이 될 수도 있을 듯 함.)</p></li></ul><p>사용방법은 docker를 사용할 것이고, 기존 docker-compose 파일에 추가해보자.</p><pre tabindex=0><code class=language-docker data-lang=docker>version: &#39;3&#39;
services:
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - &#34;2181:2181&#34;
    # Mac M1 chip 사용 시 아래 platform 추가
    platform: linux/amd64

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - &#34;9092:9092&#34;
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:29092,OUTSIDE://localhost:9092
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    depends_on:
      - zookeeper

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - &#34;8080:8080&#34;
    depends_on:
      - kafka
    environment:
      DYNAMIC_CONFIG_ENABLED: &#39;true&#39;
      KAFKA_CLUSTERS_0_NAME: wizard_local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
</code></pre><ul><li><p>kafka를 외부와 내부 리스너를 나누었다.</p></li><li><p>kafka-ui는 내부 카프카 리스너와 통신을 하고, Spring Boot 서버는 외부 카프카 리스너와 통신한다.</p></li></ul><p>위로 변경 후, 다시 docker를 실행하고, <a href=http://localhost:8080>http://localhost:8080</a> 에 접속해보자.</p><p><img loading=lazy src=https://github.com/parker1609/parker1609.github.io/assets/34755287/6845d287-d1e4-4539-9af3-7e230907b8c6 alt=kafkaui1>
메인 화면을 보면, cluster-name에 설정한 &lsquo;wizard_local&rsquo;을 볼 수 있다. 정상적으로 카프카와 연결된 것을 알 수 있다.</p><p>다시 한 번 예제에서 &ldquo;Hello Kafka&rdquo; 메시지를 만들어보자. (재실행했기 때문에 이전에 테스트했던 데이터는 초기화된 상태이다.)</p><p>그러면 다음과 같이 토픽 내에 메시지가 정상적으로 쌓인 것을 볼 수 있다.</p><p><img loading=lazy src=https://github.com/parker1609/parker1609.github.io/assets/34755287/1d27bebc-b0a6-485e-bc72-3eff03556803 alt=kafkaui2></p><h2 id=redpanda>Redpanda<a hidden class=anchor aria-hidden=true href=#redpanda>#</a></h2><p>추가 예정</p><h1 id=producer-설정>Producer 설정<a hidden class=anchor aria-hidden=true href=#producer-설정>#</a></h1><p>추가 예정</p><h1 id=consumer-설정>Consumer 설정<a hidden class=anchor aria-hidden=true href=#consumer-설정>#</a></h1><p>추가 예정</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://parker1609.github.io/tags/spring-boot/>Spring Boot</a></li><li><a href=https://parker1609.github.io/tags/kafka/>Kafka</a></li><li><a href=https://parker1609.github.io/tags/postgresql/>PostgreSQL</a></li></ul><nav class=paginav><a class=next href=https://parker1609.github.io/post/review-of-conversational-ai/><span class=title>Next »</span><br><span>대화형 AI 사용 후기와 그 미래... (feat. ChatGPT, Google Bard)</span></a></nav></footer><div id=giscus_thread><script src=https://giscus.app/client.js data-repo=parker1609/parker1609.github.io data-repo-id=R_kgDOI_VMsw data-category=Announcements data-category-id=DIC_kwDOI_VMs84CUTZR data-mapping=og:title data-strict=1 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2023 <a href=https://parker1609.github.io/>Parker Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>